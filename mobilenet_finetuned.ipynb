{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilenet_finetuned.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rvkgovind/watermarking_effects_on_classification/blob/master/mobilenet_finetuned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Lh6Op8r9rUrZ",
        "colab_type": "code",
        "outputId": "9c0071d3-54db-44c2-d80f-5387accff771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import GlobalAveragePooling2D,Flatten,Input,Activation,BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import MobileNet\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "import time\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "from keras.preprocessing import image\n",
        "from keras import regularizers,initializers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_9HppBBRvhMS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "  base_model = MobileNet(include_top=False, weights='imagenet',input_shape=(224,224,3))\n",
        "\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  x = Dense(512,use_bias=False,kernel_initializer='glorot_uniform')(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x=Dropout(0.3)(x)\n",
        "  predictions = Dense(10, kernel_initializer='uniform',activation='softmax')(x)\n",
        "  model = Model(inputs=base_model.input, outputs=predictions) \n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OxHZUm_xVLTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1737
        },
        "outputId": "d51e5024-3442-4637-8027-12db1275ce2b"
      },
      "cell_type": "code",
      "source": [
        "model=get_model()\n",
        "for i,layer in enumerate(model.layers):\n",
        "  print(i,layer.name)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "0 input_1\n",
            "1 conv1_pad\n",
            "2 conv1\n",
            "3 conv1_bn\n",
            "4 conv1_relu\n",
            "5 conv_dw_1\n",
            "6 conv_dw_1_bn\n",
            "7 conv_dw_1_relu\n",
            "8 conv_pw_1\n",
            "9 conv_pw_1_bn\n",
            "10 conv_pw_1_relu\n",
            "11 conv_pad_2\n",
            "12 conv_dw_2\n",
            "13 conv_dw_2_bn\n",
            "14 conv_dw_2_relu\n",
            "15 conv_pw_2\n",
            "16 conv_pw_2_bn\n",
            "17 conv_pw_2_relu\n",
            "18 conv_dw_3\n",
            "19 conv_dw_3_bn\n",
            "20 conv_dw_3_relu\n",
            "21 conv_pw_3\n",
            "22 conv_pw_3_bn\n",
            "23 conv_pw_3_relu\n",
            "24 conv_pad_4\n",
            "25 conv_dw_4\n",
            "26 conv_dw_4_bn\n",
            "27 conv_dw_4_relu\n",
            "28 conv_pw_4\n",
            "29 conv_pw_4_bn\n",
            "30 conv_pw_4_relu\n",
            "31 conv_dw_5\n",
            "32 conv_dw_5_bn\n",
            "33 conv_dw_5_relu\n",
            "34 conv_pw_5\n",
            "35 conv_pw_5_bn\n",
            "36 conv_pw_5_relu\n",
            "37 conv_pad_6\n",
            "38 conv_dw_6\n",
            "39 conv_dw_6_bn\n",
            "40 conv_dw_6_relu\n",
            "41 conv_pw_6\n",
            "42 conv_pw_6_bn\n",
            "43 conv_pw_6_relu\n",
            "44 conv_dw_7\n",
            "45 conv_dw_7_bn\n",
            "46 conv_dw_7_relu\n",
            "47 conv_pw_7\n",
            "48 conv_pw_7_bn\n",
            "49 conv_pw_7_relu\n",
            "50 conv_dw_8\n",
            "51 conv_dw_8_bn\n",
            "52 conv_dw_8_relu\n",
            "53 conv_pw_8\n",
            "54 conv_pw_8_bn\n",
            "55 conv_pw_8_relu\n",
            "56 conv_dw_9\n",
            "57 conv_dw_9_bn\n",
            "58 conv_dw_9_relu\n",
            "59 conv_pw_9\n",
            "60 conv_pw_9_bn\n",
            "61 conv_pw_9_relu\n",
            "62 conv_dw_10\n",
            "63 conv_dw_10_bn\n",
            "64 conv_dw_10_relu\n",
            "65 conv_pw_10\n",
            "66 conv_pw_10_bn\n",
            "67 conv_pw_10_relu\n",
            "68 conv_dw_11\n",
            "69 conv_dw_11_bn\n",
            "70 conv_dw_11_relu\n",
            "71 conv_pw_11\n",
            "72 conv_pw_11_bn\n",
            "73 conv_pw_11_relu\n",
            "74 conv_pad_12\n",
            "75 conv_dw_12\n",
            "76 conv_dw_12_bn\n",
            "77 conv_dw_12_relu\n",
            "78 conv_pw_12\n",
            "79 conv_pw_12_bn\n",
            "80 conv_pw_12_relu\n",
            "81 conv_dw_13\n",
            "82 conv_dw_13_bn\n",
            "83 conv_dw_13_relu\n",
            "84 conv_pw_13\n",
            "85 conv_pw_13_bn\n",
            "86 conv_pw_13_relu\n",
            "87 global_average_pooling2d_1\n",
            "88 dropout_1\n",
            "89 dense_1\n",
            "90 batch_normalization_1\n",
            "91 activation_1\n",
            "92 dropout_2\n",
            "93 dense_2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FBqVL-4rgmrO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def resize_dataset(X):\n",
        "  # img_arr is of shape (n, h, w, c)\n",
        "    x_resized_list = []\n",
        "    for i in range(X.shape[0]):\n",
        "        img = X[0]\n",
        "        resized_img = resize(img, (224, 224))\n",
        "        x_resized_list.append(resized_img)\n",
        "    return np.stack(x_resized_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pI92Svvg417-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalization(X,x):\n",
        "    X=X.astype('float32')\n",
        "    x=x.astype('float32')\n",
        "    mean = np.mean(X,axis=(0,1,2,3))\n",
        "    std = np.std(x, axis=(0, 1, 2, 3))\n",
        "    X = (X-mean)/std+1e-7\n",
        "    x = (x-mean)/std+1e-7\n",
        "    return X,x,mean,std\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NG23HjKc6Nvj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### np.mean()\n",
        "axis :\n",
        "If this is a tuple of ints, a mean is performed over multiple axes, instead of a single axis or all the axes as before."
      ]
    },
    {
      "metadata": {
        "id": "7h2kYXPZeQPc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "def normalize_pred(X):\n",
        "  Mean = 120.70\n",
        "  Std = 64.06\n",
        "  return (X-Mean)/((Std+1e-7))\n",
        "\n",
        "\n",
        "def extract_zip(path):\n",
        "  with ZipFile(path, 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n",
        "  print(\"Extracted images to the root dir\")\n",
        "\n",
        "def vizualize_data(X_train):\n",
        "  #print(\"shape of X_train:\",X_train.shape)\n",
        "  #print(\"shape of Y_train:\",Y_train.shape)\n",
        "  #print(\"shape of X_test:\",X_test.shape)\n",
        "  #print(\"shape of Y_test:\",X_test.shape)\n",
        "  fig=plt.figure()\n",
        "  for i in range(1,11):\n",
        "    a=fig.add_subplot(2,5,i)\n",
        "    imgplot=plt.imshow(X_train[i-1])\n",
        "\n",
        "def prep_testdata(path):\n",
        "  X_val=np.zeros([100,224,224,3])\n",
        "  Y_val=np.zeros([100],dtype='uint8')\n",
        "  i=0\n",
        "  test_dictionary={\"aeroplane\":0,\"automobile\":1,'bird':2,'cat':3,'deer':4,'dog':5,'frog':6,'horse':7,'ship':8,'truck':9}\n",
        "  for file in os.listdir(path):\n",
        "    for key,value in test_dictionary.items():\n",
        "      if file==key:\n",
        "        file_path=os.path.join(path,file)\n",
        "        for images in os.listdir(file_path):\n",
        "          img_path=os.path.join(file_path,images)\n",
        "          img = image.load_img(img_path, target_size=(224, 224))\n",
        "          x = image.img_to_array(img)\n",
        "          x=np.asarray(x,dtype='uint8')  \n",
        "          #cv2_imshow(img)\n",
        "          X_val[i]=x\n",
        "          Y_val[i]=value\n",
        "          #print(key)\n",
        "          #print(value)\n",
        "          i+=1\n",
        "  return X_val,Y_val,test_dictionary\n",
        "def gen_batches_test(X_test,Y_test,BS):\n",
        "  #infinite loop\n",
        "  while True:\n",
        "    X_resized=[]\n",
        "    Y_labels=[]\n",
        "    i=0\n",
        "    while len(X_resized)<BS:\n",
        "      X = X_train[i]\n",
        "      X= resize(X, (224, 224))\n",
        "      X_resized.append(X)\n",
        "      Y_labels.append(Y_train[i])\n",
        "      #print(np.array(X_resized).shape)\n",
        "      #print(np.array(Y_labels).shape)\n",
        "      i+=1\n",
        "      \n",
        "    yield (np.array(X_resized),np.array(Y_labels))\n",
        "\n",
        "def gen_batches_train(X_train,Y_train,BS,aug=None):\n",
        "  #infinite loop\n",
        "  while True:\n",
        "    X_resized=[]\n",
        "    Y_labels=[]\n",
        "    i=0\n",
        "    while len(X_resized)<BS:\n",
        "      X = X_train[i]\n",
        "      X= resize(X, (224, 224))\n",
        "      X_resized.append(X)\n",
        "      Y_labels.append(Y_train[i])\n",
        "      #print(np.array(X_resized).shape)\n",
        "      #print(np.array(Y_labels).shape)\n",
        "      i+=1\n",
        "      # if the data augmentation object is not None, apply it\n",
        "    if aug is not None:\n",
        "        (X_resized, Y_labels) = next(aug.flow(np.array(X_resized),Y_labels, batch_size=BS))\n",
        "      \n",
        "    yield (np.array(X_resized),np.array(Y_labels))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6HDAzGF1xKmO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model,X_train,Y_train,X_test,Y_test):\n",
        "  batch_size=256\n",
        "  epochs=10\n",
        "  #load the dataset and spilt to train and validate\n",
        "  #normalize the dataset to mean 0 and variance 1\n",
        "  for layer in model.layers[:86]:\n",
        "    layer.trainable=False\n",
        "  for layer in model.layers[86:]:\n",
        "    layer.trainable=True\n",
        "  \n",
        "  X_train = preprocess_input(X_train)\n",
        "  X_test=preprocess_input(X_test)\n",
        "  #conver the targets to one hot vectors using keras.utils.to_categorical\n",
        "  #data augmentation\n",
        "  aug = ImageDataGenerator(zca_whitening=True,horizontal_flip=True)\n",
        "  \n",
        "  \n",
        "  # compute quantities required for featurewise normalization\n",
        "  # (std, mean, and principal components if ZCA whitening is applied)\n",
        "  datagen=gen_batches_train(X_train,Y_train,batch_size,aug=None)\n",
        "  testdata_gen=gen_batches_test(X_test,Y_test,batch_size)\n",
        "  model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy']) \n",
        "  filepath=\"weights.best.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "  callbacks_list = [checkpoint]\n",
        "  # fits the model on batches with real-time data augmentation:\n",
        "  history=model.fit_generator(datagen,steps_per_epoch=X_train.shape[0]// batch_size, epochs=epochs,\n",
        "                              validation_data=testdata_gen,validation_steps=X_test.shape[0]//batch_size,callbacks=callbacks_list)\n",
        "  \n",
        "  #compile the model by mentioning the loss function,optimizer, accuracy to measure\n",
        " \n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SoDkNOblAfjj",
        "colab_type": "code",
        "outputId": "f200a1a9-9656-41a4-b91b-25966840bef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "cell_type": "code",
      "source": [
        "if __name__=='__main__':\n",
        "  start=time.time()\n",
        "  #[X_train, Y_train,X_test, Y_test]= load_cifar10_data(img_rows,img_cols)\n",
        "  (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "  Y_train = keras.utils.to_categorical(Y_train, 10)\n",
        "  Y_test = keras.utils.to_categorical(Y_test, 10)\n",
        "  if os.path.exists('./weights.best.hdf5'):\n",
        "    model=get_model()\n",
        "    extract_zip('test.zip')\n",
        "    test_lab={}\n",
        "    [X_cross,Y_cross,test_lab]=prep_testdata('./test')\n",
        "    #vizualize_data(X)\n",
        "    #X_norm=normalize_pred(X)\n",
        "    Y=keras.utils.to_categorical(Y_cross,10)\n",
        "    model.load_weights('./weights.best.hdf5')\n",
        "    i=0\n",
        "    k=list(test_lab.keys())\n",
        "    v=list(test_lab.values())\n",
        "    residual=[] \n",
        "    for i in range(0,100):\n",
        "      imag = X_cross[i][:, :, (2, 1, 0)]\n",
        "      cv2_imshow(imag)\n",
        "      x=np.expand_dims(X_cross[i], axis=0)\n",
        "      x=preprocess_input(x)\n",
        "      predict=model.predict(x)\n",
        "      residual.append(np.argmax(predict)!=np.argmax(Y[i]))\n",
        "      prediction=np.argmax(predict)\n",
        "      true_label=np.argmax(Y[i])\n",
        "      print('prediction:',k[v.index(prediction)])\n",
        "      print('true label:',k[v.index(true_label)])\n",
        "      i+=1\n",
        "      \n",
        "    loss = sum(residual)/len(residual)\n",
        "    print('loss during testing with test images:',loss)\n",
        "    \n",
        "  else:\n",
        "    model=get_model()\n",
        "    trained_model=train_model(model,X_train,Y_train,X_test,Y_test)\n",
        "  print(\"time taken for execution:\",time.time()-start)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:334: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
            "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "195/195 [==============================] - 426s 2s/step - loss: 0.1115 - acc: 0.9781 - val_loss: 0.5998 - val_acc: 0.8242\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.82422, saving model to weights.best.hdf5\n",
            "Epoch 2/10\n",
            "195/195 [==============================] - 397s 2s/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5831 - val_acc: 0.8164\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.82422\n",
            "Epoch 3/10\n",
            "195/195 [==============================] - 401s 2s/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5594 - val_acc: 0.8359\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.82422 to 0.83594, saving model to weights.best.hdf5\n",
            "Epoch 4/10\n",
            "195/195 [==============================] - 403s 2s/step - loss: 6.3368e-04 - acc: 1.0000 - val_loss: 0.5774 - val_acc: 0.8242\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.83594\n",
            "Epoch 5/10\n",
            "195/195 [==============================] - 402s 2s/step - loss: 3.9731e-04 - acc: 1.0000 - val_loss: 0.5686 - val_acc: 0.8164\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.83594\n",
            "Epoch 6/10\n",
            "195/195 [==============================] - 401s 2s/step - loss: 3.0923e-04 - acc: 1.0000 - val_loss: 0.5671 - val_acc: 0.8164\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.83594\n",
            "Epoch 7/10\n",
            "195/195 [==============================] - 404s 2s/step - loss: 2.2611e-04 - acc: 1.0000 - val_loss: 0.5419 - val_acc: 0.8203\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.83594\n",
            "Epoch 8/10\n",
            "195/195 [==============================] - 403s 2s/step - loss: 1.9311e-04 - acc: 1.0000 - val_loss: 0.5719 - val_acc: 0.8164\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.83594\n",
            "Epoch 9/10\n",
            "195/195 [==============================] - 402s 2s/step - loss: 1.3748e-04 - acc: 1.0000 - val_loss: 0.5626 - val_acc: 0.8242\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.83594\n",
            "Epoch 10/10\n",
            "195/195 [==============================] - 405s 2s/step - loss: 1.1141e-04 - acc: 1.0000 - val_loss: 0.5696 - val_acc: 0.8281\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.83594\n",
            "time taken for execution: 4062.216627597809\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}